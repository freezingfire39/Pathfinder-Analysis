{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "50db99c2",
   "metadata": {},
   "source": [
    "#search_result = investpy.search_quotes(text='Blackrock', products=['funds'],\n",
    "#                                       countries=['united states'], n_results=1)\n",
    "import investpy\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import yfinance as yf\n",
    "#print (search_result)\n",
    "df = investpy.get_funds_list(country=\"China\")\n",
    "print(len(df))\n",
    "print (df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9d42c9ee",
   "metadata": {},
   "source": [
    "df = investpy.get_fund_information(fund='Manulife Teda Renaissance Biz Alloc Fd',country='China')\n",
    "print(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4d3e3a69",
   "metadata": {},
   "source": [
    "import nasdaqdatalink\n",
    "nasdaqdatalink.ApiConfig.api_key = 'znxYqt7DpE3soUMDRfGE'\n",
    "security = '510500' ##target name\n",
    "df_target = nasdaqdatalink.get_table('DY/EMPRIA', security=security)\n",
    "df_target = df_target.iloc[::-1]\n",
    "df_target.set_index('date',inplace=True)\n",
    "df_target.index = pd.to_datetime(df_target.index)\n",
    "print (df_target)\n",
    "df_target_2 = nasdaqdatalink.get_table('DY/EMMONA', security='000010')\n",
    "print (df_target_2)\n",
    "df_target_3 = nasdaqdatalink.get_table('DY/EMNAVA', security=security)\n",
    "print (df_target_3)\n",
    "df_target_4 = nasdaqdatalink.get_table('DY/EMNAVADJA', security=security)\n",
    "print (df_target_4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "93aadb8d",
   "metadata": {},
   "source": [
    "#index_etf_1 = yf.download(\"510050.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##A50\n",
    "#index_etf_2 = yf.download(\"159901.SZ\", start=\"2021-06-01\", end=\"2023-11-15\") ##Shenzhen100\n",
    "#index_etf_3 = yf.download(\"159949.SZ\", start=\"2021-06-01\", end=\"2023-11-15\") ##chuangye50\n",
    "#index_etf_4 = yf.download(\"510300.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##husheng300\n",
    "#index_etf_5 = yf.download(\"510500.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##zhongzheng500\n",
    "#index_etf_6 = yf.download(\"512100.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##zhongzheng1000\n",
    "#index_etf_7 = yf.download(\"588000.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##kechuang50\n",
    "#index_etf_8 = yf.download(\"510900.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##HangSeng\n",
    "start = datetime(2017, 1, 1)\n",
    "symbols_list = ['510050.SS', '159901.SZ', '159949.SZ', '510300.SS', '510500.SS', '512100.SS', '588000.SS', '510900.SS']\n",
    "#array to store prices\n",
    "symbols=[]\n",
    "\n",
    "#array to store prices\n",
    "symbols=[]\n",
    "for ticker in symbols_list:     \n",
    "    r = yf.download(ticker, start=start, end=\"2024-04-05\")\n",
    "    # add a symbol column   \n",
    "    r['Symbol'] = ticker    \n",
    "    symbols.append(r)\n",
    "# concatenate into df\n",
    "df = pd.concat(symbols)\n",
    "df = df.reset_index()\n",
    "df = df[['Date', 'Close', 'Symbol']]\n",
    "df.head()\n",
    "df_pivot=df.pivot('Date','Symbol','Close').reset_index()\n",
    "\n",
    "\n",
    "df_pivot.set_index('Date',inplace=True)\n",
    "df_pivot.index = pd.to_datetime(df_pivot.index)\n",
    "\n",
    "df_pivot.head()\n",
    "df_pivot[security] = df_target['close']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (df_pivot)\n",
    "\n",
    "\n",
    "\n",
    "corr_df = df_pivot.corr(method='pearson')\n",
    "#reset symbol as index (rather than 0-X)\n",
    "corr_df.head().reset_index()\n",
    "#del corr_df.index.name\n",
    "corr_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(13, 8))\n",
    "seaborn.heatmap(corr_df, annot=True, cmap='RdYlGn')\n",
    "plt.figure()\n",
    "df_new = corr_df[security].drop(corr_df[security].idxmax())\n",
    "comp_1_name = df_new.idxmax()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d0f1a73",
   "metadata": {},
   "source": [
    "#index_etf_1 = yf.download(\"510230.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##finance\n",
    "#index_etf_2 = yf.download(\"512010.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##Pharmaceutical\n",
    "#index_etf_3 = yf.download(\"512170.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##healthcare\n",
    "#index_etf_4 = yf.download(\"515170.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##food&bev\n",
    "#index_etf_5 = yf.download(\"516160.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##new energy\n",
    "#index_etf_6 = yf.download(\"512480.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##semiconductor\n",
    "#index_etf_7 = yf.download(\"515230.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##software\n",
    "#index_etf_8 = yf.download(\"512660.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##military\n",
    "#index_etf_9 = yf.download(\"516220.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##chemistry\n",
    "#index_etf_10 = yf.download(\"516800.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##manufacturing\n",
    "#index_etf_11 = yf.download(\"512400.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##metal\n",
    "#index_etf_12 = yf.download(\"159825.SZ\", start=\"2021-06-01\", end=\"2023-11-15\") ##agriculture\n",
    "#index_etf_13 = yf.download(\"516950.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##infrastructure\n",
    "#index_etf_14 = yf.download(\"516070.SS\", start=\"2021-06-01\", end=\"2023-11-15\") ##environmental\n",
    "\n",
    "start = datetime(2017, 1, 1)\n",
    "symbols_list = ['510230.SS', '512010.SS', '512170.SS', '515170.SS', '512480.SS', '515230.SS', '512660.SS', '516220.SS','516800.SS',\"512400.SS\",\"159825.SZ\",\"516950.SS\",\"516070.SS\"]\n",
    "#array to store prices\n",
    "symbols=[]\n",
    "\n",
    "#array to store prices\n",
    "symbols=[]\n",
    "for ticker in symbols_list:     \n",
    "    r = yf.download(ticker, start=start, end=\"2024-04-05\")\n",
    "    # add a symbol column   \n",
    "    r['Symbol'] = ticker    \n",
    "    symbols.append(r)\n",
    "# concatenate into df\n",
    "df = pd.concat(symbols)\n",
    "df = df.reset_index()\n",
    "df = df[['Date', 'Close', 'Symbol']]\n",
    "df.head()\n",
    "df_pivot=df.pivot('Date','Symbol','Close').reset_index()\n",
    "\n",
    "\n",
    "df_pivot.set_index('Date',inplace=True)\n",
    "df_pivot.index = pd.to_datetime(df_pivot.index)\n",
    "\n",
    "df_pivot.head()\n",
    "df_pivot[security] = df_target['close']\n",
    "\n",
    "corr_df = df_pivot.corr(method='pearson')\n",
    "#reset symbol as index (rather than 0-X)\n",
    "corr_df.head().reset_index()\n",
    "#del corr_df.index.name\n",
    "corr_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(13, 8))\n",
    "seaborn.heatmap(corr_df, annot=True, cmap='RdYlGn')\n",
    "plt.figure()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "00e79d27",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_new = corr_df[security].drop(corr_df[security].idxmax())\n",
    "comp_2_name = df_new.idxmax()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "56255cb8",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "df_target['return'] = df_target['close'].pct_change()\n",
    "df_target['return'].hist(bins=50, ax=ax1)\n",
    "ax1.set_xlabel('Return')\n",
    "ax1.set_ylabel('Sample')\n",
    "ax1.set_title('Return distribution')\n",
    "plt.show()\n",
    "comp_1 = yf.download(comp_1_name, start=start, end=\"2024-04-05\") ##chuangye50\n",
    "comp_2 = yf.download(comp_2_name , start=start, end=\"2024-04-05\")\n",
    "df_target['gap_1'] = df_target['return']-comp_1['Close'].pct_change()\n",
    "df_target['gap_2'] = df_target['return']-comp_2['Close'].pct_change()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "df_target['return'] = df_target['close'].pct_change()\n",
    "df_target['gap_2'].hist(bins=50, ax=ax1)\n",
    "ax1.set_xlabel('Return')\n",
    "ax1.set_ylabel('Sample')\n",
    "ax1.set_title('Return distribution')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d926dd01",
   "metadata": {},
   "source": [
    "risk_free_rate=0.0\n",
    "df_target['rolling_SR'] = df_target['return'].rolling(60).apply(lambda x: (x.mean() - risk_free_rate) / x.std(), raw = True)\n",
    "df_target['rolling_SR'].plot()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fef88da7",
   "metadata": {},
   "source": [
    "wealth_index = 1000*(1+df_target['return']).cumprod()\n",
    "previous_peaks = wealth_index.cummax()\n",
    "drawdown = (wealth_index-previous_peaks)/previous_peaks\n",
    "drawdown.plot()\n",
    "pf.show_worst_drawdown_periods(df_target['return'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8facd82a",
   "metadata": {},
   "source": [
    "def market_capture_ratio(returns):\n",
    "    \"\"\"\n",
    "    Function to calculate the upside and downside capture for a given set of returns.\n",
    "    The function is set up so that the investment's returns are in the first column of the dataframe\n",
    "    and the index returns are the second column.\n",
    "    :param returns: pd.DataFrame of asset class returns\n",
    "    :return: pd.DataFrame of market capture results\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize an empty dataframe to store the results\n",
    "    df_mkt_capture = pd.DataFrame()\n",
    "\n",
    "    # 1) Upside capture ratio\n",
    "    # a) Isolate positive periods of the index\n",
    "    up_market = returns[returns.iloc[:, -1] >= 0]\n",
    "\n",
    "    # b) Geometrically link the returns\n",
    "    up_linked_rets = ((1 + up_market).product(axis=0)) - 1\n",
    "\n",
    "    # c) Calculate the ratio, multiply by 100 and round to 2 decimals to show in percent\n",
    "    up_ratio = (up_linked_rets / up_linked_rets.iloc[-1] * 100).round(2)\n",
    "\n",
    "    # 2) Downside capture ratio\n",
    "    # a) Isolate negative periods of the index\n",
    "    down_market = returns[returns.iloc[:, -1] < 0]\n",
    "\n",
    "    # b) Geometrically link the returns\n",
    "    down_linked_rets = ((1 + down_market).product(axis=0)) - 1\n",
    "\n",
    "    # c) Calculate the ratio, multiply by 100 and round to 2 decimals to show in percent\n",
    "    down_ratio = (down_linked_rets / down_linked_rets.iloc[-1] * 100).round(2)\n",
    "\n",
    "    # 3) Combine to produce our final dataframe\n",
    "    df_mkt_capture = pd.concat([up_ratio, down_ratio], axis=1)\n",
    "\n",
    "    df_mkt_capture.columns = ['Upside Capture', 'Downside Capture']\n",
    "\n",
    "    return df_mkt_capture\n",
    "\n",
    "df_target['comp_1'] = comp_2['Close']\n",
    "print (df_target)\n",
    "# Keep only the adjusted close columns\n",
    "df1 = df_target[['close', 'comp_1']]\n",
    "\n",
    "# Resample to month end and calculate the monthly percent change\n",
    "df_rets_monthly = df1.resample('M').last().pct_change().dropna()\n",
    "\n",
    "# Calculate the market capture ratios\n",
    "df_mkt_capture = market_capture_ratio(df_rets_monthly)\n",
    "\n",
    "print(df_mkt_capture)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ea265c94",
   "metadata": {},
   "source": [
    "#\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df_target['alpha'] = 0\n",
    "df_target['alpha'] = df_target['alpha'].astype('float64')\n",
    "df_target['beta'] = 0\n",
    "df_target['beta'] = df_target['beta'].astype('float64')\n",
    "\n",
    "df_drop=[]\n",
    "for i in df_target.index:\n",
    "    if i not in comp_2.index:\n",
    "        df_drop.append(i)\n",
    "df_target = df_target.drop(df_drop, axis=0)\n",
    "\n",
    "\n",
    "df_drop=[]\n",
    "for i in comp_2.index:\n",
    "    if i not in df_target.index:\n",
    "        df_drop.append(i)\n",
    "comp_2 = comp_2.drop(df_drop, axis=0)\n",
    "comp_2['return'] = comp_2['Close'].pct_change()\n",
    "for i in range(len(df_target)):\n",
    "    if i<90:\n",
    "        continue\n",
    "    df_temp_1 = df_target.iloc[i-90:i] \n",
    "    df_temp_2 = comp_2.iloc[i-90:i] \n",
    "    #print (df_temp_1)\n",
    "    (beta, alpha) = stats.linregress(df_temp_2['return'], df_temp_1['return'])[0:2]\n",
    "    df_target['alpha'][i]=alpha\n",
    "    df_target['beta'][i]=beta\n",
    "df_target['alpha'].plot()\n",
    "print (df_target)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e64ec577",
   "metadata": {},
   "source": [
    "df_target['beta'].plot()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c2fa75e9",
   "metadata": {},
   "source": [
    "\n",
    "security_1 = '512170'\n",
    "security_2 = '515170'\n",
    "security_3 = '512660'\n",
    "security_4 = '516800'\n",
    "security_5 = \"512400\"\n",
    "\n",
    "df_port_1 = nasdaqdatalink.get_table('DY/EMPRIA', security=security_1)\n",
    "df_port_1  = df_port_1 .iloc[::-1]\n",
    "df_port_1 .set_index('date',inplace=True)\n",
    "df_port_1 .index = pd.to_datetime(df_port_1 .index)\n",
    "\n",
    "\n",
    "df_port_2 = nasdaqdatalink.get_table('DY/EMPRIA', security=security_2)\n",
    "df_port_2 = df_port_2.iloc[::-1]\n",
    "df_port_2.set_index('date',inplace=True)\n",
    "df_port_2.index = pd.to_datetime(df_port_2.index)\n",
    "\n",
    "df_port_3 = nasdaqdatalink.get_table('DY/EMPRIA', security=security_3)\n",
    "df_port_3 = df_port_3.iloc[::-1]\n",
    "df_port_3.set_index('date',inplace=True)\n",
    "df_port_3.index = pd.to_datetime(df_port_3.index)\n",
    "\n",
    "df_port_4 = nasdaqdatalink.get_table('DY/EMPRIA', security=security_4)\n",
    "df_port_4 = df_port_4.iloc[::-1]\n",
    "df_port_4.set_index('date',inplace=True)\n",
    "df_port_4.index = pd.to_datetime(df_port_4.index)\n",
    "\n",
    "df_port_5 = nasdaqdatalink.get_table('DY/EMPRIA', security=security_5)\n",
    "df_port_5 = df_port_5.iloc[::-1]\n",
    "df_port_5.set_index('date',inplace=True)\n",
    "df_port_5.index = pd.to_datetime(df_port_5.index)\n",
    "\n",
    "df_target['port_1_return'] = df_port_1['close'].pct_change()\n",
    "df_target['port_2_return'] = df_port_2['close'].pct_change()\n",
    "\n",
    "df_target['port_1_close'] = df_port_1['close']\n",
    "df_target['port_2_close'] = df_port_2['close']\n",
    "df_target['port_3_close'] = df_port_3['close']\n",
    "df_target['port_4_close'] = df_port_4['close']\n",
    "df_target['port_5_close'] = df_port_5['close']\n",
    "returns = df_target[['return','port_1_return','port_2_return']]\n",
    "\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "cov_matrix\n",
    "weights = np.array([.25, .45, .3])\n",
    "\n",
    "# Set an initial investment level\n",
    "initial_investment = 1000000\n",
    "avg_rets = returns.mean()\n",
    "\n",
    "# Calculate mean returns for portfolio overall, \n",
    "# using dot product to \n",
    "# normalize individual means against investment weights\n",
    " # https://en.wikipedia.org/wiki/Dot_product#:~:targetText=In%20mathematics%2C%20the%20dot%20product,and%20returns%20a%20single%20number.\n",
    "port_mean = avg_rets.dot(weights)\n",
    "\n",
    "# Calculate portfolio standard deviation\n",
    "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    "\n",
    "# Calculate mean of investment\n",
    "mean_investment = (1+port_mean) * initial_investment\n",
    "\n",
    "# Calculate standard deviation of investmnet\n",
    "stdev_investment = initial_investment * port_stdev\n",
    "conf_level1 = 0.05\n",
    "\n",
    "# Using SciPy ppf method to generate values for the\n",
    "# inverse cumulative distribution function to a normal distribution\n",
    "# Plugging in the mean, standard deviation of our portfolio\n",
    "# as calculated above\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "from scipy.stats import norm\n",
    "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)\n",
    "var_1d1 = initial_investment - cutoff1\n",
    "var_array = []\n",
    "num_days = int(15)\n",
    "for x in range(1, num_days+1):    \n",
    "    var_array.append(np.round(var_1d1 * np.sqrt(x),2))\n",
    "    print(str(x) + \" day VaR @ 95% confidence: \" + str(np.round(var_1d1 * np.sqrt(x),2)))\n",
    "\n",
    "# Build plot\n",
    "plt.xlabel(\"Day #\")\n",
    "plt.ylabel(\"Max portfolio loss (USD)\")\n",
    "plt.title(\"Max portfolio loss (VaR) over 15-day period\")\n",
    "plt.plot(var_array, \"r\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e81b72c3",
   "metadata": {},
   "source": [
    "returns = df_target[['return','port_1_return','port_2_return']]\n",
    "annualized_vol = returns.std()*np.sqrt(12)\n",
    "annualized_vol.plot.bar()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c54452e9",
   "metadata": {},
   "source": [
    "##port opt\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "\n",
    "\n",
    "portfolio = df_target[['close','port_1_close','port_2_close','port_3_close','port_4_close','port_5_close']]\n",
    "print (portfolio)\n",
    "mu = mean_historical_return(portfolio)\n",
    "S = CovarianceShrinkage(portfolio).ledoit_wolf()\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "print (mu)\n",
    "print (S)\n",
    "ef = EfficientFrontier(mu, S)\n",
    "weights = ef.max_quadratic_utility() \n",
    "\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(dict(cleaned_weights))\n",
    "ef.portfolio_performance(verbose=True)\n",
    "\n",
    "from pypfopt import HRPOpt\n",
    "returns = portfolio.pct_change().dropna()\n",
    "hrp = HRPOpt(returns)\n",
    "hrp_weights = hrp.optimize()\n",
    "hrp.portfolio_performance(verbose=True)\n",
    "print(dict(hrp_weights))\n",
    "from pypfopt.efficient_frontier import EfficientCVaR\n",
    "S = portfolio.cov()\n",
    "ef_cvar = EfficientCVaR(mu, S)\n",
    "cvar_weights = ef_cvar.min_cvar()\n",
    "\n",
    "cleaned_weights = ef_cvar.clean_weights()\n",
    "print(dict(cleaned_weights))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61952dd5",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
